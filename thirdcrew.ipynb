{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agentic Sales Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "from helper import load_env\n",
    "load_env()\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_MODEL_NAME'] = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for YAML configurations\n",
    "files = {\n",
    "    'lead_agents': 'config/lead_qualification_agents.yaml',\n",
    "    'lead_tasks': 'config/lead_qualification_tasks.yaml',\n",
    "    'email_agents': 'config/email_engagement_agents.yaml',\n",
    "    'email_tasks': 'config/email_engagement_tasks.yaml'\n",
    "}\n",
    "\n",
    "# Load configurations from YAML files\n",
    "configs = {}\n",
    "for config_type, file_path in files.items():\n",
    "    with open(file_path, 'r') as file:\n",
    "        configs[config_type] = yaml.safe_load(file)\n",
    "\n",
    "# Assign loaded configurations to specific variables\n",
    "lead_agents_config = configs['lead_agents']\n",
    "lead_tasks_config = configs['lead_tasks']\n",
    "email_agents_config = configs['email_agents']\n",
    "email_tasks_config = configs['email_tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, Optional, List, Set, Tuple\n",
    "\n",
    "class LeadPersonalInfo(BaseModel):\n",
    "    name: str = Field(..., description=\"The full name of the lead.\")\n",
    "    job_title: str = Field(..., description=\"The job title of the lead.\")\n",
    "    role_relevance: int = Field(..., ge=0, le=10, description=\"A score representing how relevant the lead's role is to the decision-making process (0-10).\")\n",
    "    professional_background: Optional[str] = Field(..., description=\"A brief description of the lead's professional background.\")\n",
    "\n",
    "class CompanyInfo(BaseModel):\n",
    "    company_name: str = Field(..., description=\"The name of the company the lead works for.\")\n",
    "    industry: str = Field(..., description=\"The industry in which the company operates.\")\n",
    "    company_size: int = Field(..., description=\"The size of the company in terms of employee count.\")\n",
    "    revenue: Optional[float] = Field(None, description=\"The annual revenue of the company, if available.\")\n",
    "    market_presence: int = Field(..., ge=0, le=10, description=\"A score representing the company's market presence (0-10).\")\n",
    "\n",
    "class LeadScore(BaseModel):\n",
    "    score: int = Field(..., ge=0, le=100, description=\"The final score assigned to the lead (0-100).\")\n",
    "    scoring_criteria: List[str] = Field(..., description=\"The criteria used to determine the lead's score.\")\n",
    "    validation_notes: Optional[str] = Field(None, description=\"Any notes regarding the validation of the lead score.\")\n",
    "\n",
    "class LeadScoringResult(BaseModel):\n",
    "    personal_info: LeadPersonalInfo = Field(..., description=\"Personal information about the lead.\")\n",
    "    company_info: CompanyInfo = Field(..., description=\"Information about the lead's company.\")\n",
    "    lead_score: LeadScore = Field(..., description=\"The calculated score and related information for the lead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import SerperDevTool, ScrapeWebsiteTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lead Qualification Crew, Agents and Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-01 22:03:02,711 - 128752929796224 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "# Creating Agents\n",
    "lead_data_agent = Agent(\n",
    "  config=lead_agents_config['lead_data_agent'],\n",
    "  tools=[SerperDevTool(), ScrapeWebsiteTool()]\n",
    ")\n",
    "\n",
    "cultural_fit_agent = Agent(\n",
    "  config=lead_agents_config['cultural_fit_agent'],\n",
    "  tools=[SerperDevTool(), ScrapeWebsiteTool()]\n",
    ")\n",
    "\n",
    "scoring_validation_agent = Agent(\n",
    "  config=lead_agents_config['scoring_validation_agent'],\n",
    "  tools=[SerperDevTool(), ScrapeWebsiteTool()]\n",
    ")\n",
    "\n",
    "# Creating Tasks\n",
    "lead_data_task = Task(\n",
    "  config=lead_tasks_config['lead_data_collection'],\n",
    "  agent=lead_data_agent\n",
    ")\n",
    "\n",
    "cultural_fit_task = Task(\n",
    "  config=lead_tasks_config['cultural_fit_analysis'],\n",
    "  agent=cultural_fit_agent\n",
    ")\n",
    "\n",
    "scoring_validation_task = Task(\n",
    "  config=lead_tasks_config['lead_scoring_and_validation'],\n",
    "  agent=scoring_validation_agent,\n",
    "  context=[lead_data_task, cultural_fit_task],\n",
    "  output_pydantic=LeadScoringResult\n",
    ")\n",
    "\n",
    "# Creating Crew\n",
    "lead_scoring_crew = Crew(\n",
    "  agents=[\n",
    "    lead_data_agent,\n",
    "    cultural_fit_agent,\n",
    "    scoring_validation_agent\n",
    "  ],\n",
    "  tasks=[\n",
    "    lead_data_task,\n",
    "    cultural_fit_task,\n",
    "    scoring_validation_task\n",
    "  ],\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email Engagement Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-01 22:03:02,731 - 128752929796224 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "# Creating Agents\n",
    "email_content_specialist = Agent(\n",
    "  config=email_agents_config['email_content_specialist']\n",
    ")\n",
    "\n",
    "engagement_strategist = Agent(\n",
    "  config=email_agents_config['engagement_strategist']\n",
    ")\n",
    "\n",
    "# Creating Tasks\n",
    "email_drafting = Task(\n",
    "  config=email_tasks_config['email_drafting'],\n",
    "  agent=email_content_specialist\n",
    ")\n",
    "\n",
    "engagement_optimization = Task(\n",
    "  config=email_tasks_config['engagement_optimization'],\n",
    "  agent=engagement_strategist\n",
    ")\n",
    "\n",
    "# Creating Crew\n",
    "email_writing_crew = Crew(\n",
    "  agents=[\n",
    "    email_content_specialist,\n",
    "    engagement_strategist\n",
    "  ],\n",
    "  tasks=[\n",
    "    email_drafting,\n",
    "    engagement_optimization\n",
    "  ],\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Complete Sales Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Flow\n",
    "from crewai.flow.flow import listen, start\n",
    "\n",
    "class SalesPipeline(Flow):\n",
    "    @start()\n",
    "    def fetch_leads(self):\n",
    "        # Pull our leads from the database\n",
    "        leads = [\n",
    "            {\n",
    "                \"lead_data\": {\n",
    "                    \"name\": \"João Moura\",\n",
    "                    \"job_title\": \"Director of Engineering\",\n",
    "                    \"company\": \"Clearbit\",\n",
    "                    \"email\": \"joao@clearbit.com\",\n",
    "                    \"use_case\": \"Using AI Agent to do better data enrichment.\"\n",
    "                },\n",
    "            },\n",
    "        ]\n",
    "        return leads\n",
    "\n",
    "    @listen(fetch_leads)\n",
    "    def score_leads(self, leads):\n",
    "        scores = lead_scoring_crew.kickoff_for_each(leads)\n",
    "        self.state[\"score_crews_results\"] = scores\n",
    "        return scores\n",
    "\n",
    "    @listen(score_leads)\n",
    "    def store_leads_score(self, scores):\n",
    "        # Here we would store the scores in the database\n",
    "        return scores\n",
    "\n",
    "    @listen(score_leads)\n",
    "    def filter_leads(self, scores):\n",
    "        return [score for score in scores if score['lead_score'].score > 70]\n",
    "\n",
    "    @listen(filter_leads)\n",
    "    def write_email(self, leads):\n",
    "        scored_leads = [lead.to_dict() for lead in leads]\n",
    "        emails = email_writing_crew.kickoff_for_each(scored_leads)\n",
    "        return emails\n",
    "\n",
    "    @listen(write_email)\n",
    "    def send_email(self, emails):\n",
    "        # Here we would send the emails to the leads\n",
    "        return emails\n",
    "\n",
    "flow = SalesPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as crewai_flow.html\n"
     ]
    }
   ],
   "source": [
    "flow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"150%\"\n",
       "            height=\"600\"\n",
       "            src=\"./crewai_flow.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7519364b3bf0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='./crewai_flow.html', width='150%', height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m emails \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/agents-crewai/agents-crewai/lib/python3.12/site-packages/crewai/flow/flow.py:258\u001b[0m, in \u001b[0;36mFlow.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_state(inputs)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/asyncio/runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "emails = await flow.kickoff_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'score_crews_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Convert UsageMetrics instance to a DataFrame\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_usage_metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore_crews_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtoken_usage\u001b[38;5;241m.\u001b[39mdict()])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate total costs\u001b[39;00m\n\u001b[1;32m      7\u001b[0m costs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.150\u001b[39m \u001b[38;5;241m*\u001b[39m df_usage_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1_000_000\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'score_crews_results'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert UsageMetrics instance to a DataFrame\n",
    "df_usage_metrics = pd.DataFrame([flow.state[\"score_crews_results\"][0].token_usage.dict()])\n",
    "\n",
    "# Calculate total costs\n",
    "costs = 0.150 * df_usage_metrics['total_tokens'].sum() / 1_000_000\n",
    "print(f\"Total costs: ${costs:.4f}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "df_usage_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert UsageMetrics instance to a DataFrame\n",
    "df_usage_metrics = pd.DataFrame([emails[0].token_usage.dict()])\n",
    "\n",
    "# Calculate total costs\n",
    "costs = 0.150 * df_usage_metrics['total_tokens'].sum() / 1_000_000\n",
    "print(f\"Total costs: ${costs:.4f}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "df_usage_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = flow.state[\"score_crews_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "lead_scoring_result = scores[0].pydantic\n",
    "\n",
    "# Create a dictionary with the nested structure flattened\n",
    "data = {\n",
    "    'Name': lead_scoring_result.personal_info.name,\n",
    "    'Job Title': lead_scoring_result.personal_info.job_title,\n",
    "    'Role Relevance': lead_scoring_result.personal_info.role_relevance,\n",
    "    'Professional Background': lead_scoring_result.personal_info.professional_background,\n",
    "    'Company Name': lead_scoring_result.company_info.company_name,\n",
    "    'Industry': lead_scoring_result.company_info.industry,\n",
    "    'Company Size': lead_scoring_result.company_info.company_size,\n",
    "    'Revenue': lead_scoring_result.company_info.revenue,\n",
    "    'Market Presence': lead_scoring_result.company_info.market_presence,\n",
    "    'Lead Score': lead_scoring_result.lead_score.score,\n",
    "    'Scoring Criteria': ', '.join(lead_scoring_result.lead_score.scoring_criteria),\n",
    "    'Validation Notes': lead_scoring_result.lead_score.validation_notes\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame.from_dict(data, orient='index', columns=['Value'])\n",
    "\n",
    "# Reset the index to turn the original column names into a regular column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Rename the index column to 'Attribute'\n",
    "df = df.rename(columns={'index': 'Attribute'})\n",
    "\n",
    "# Create HTML table with bold attributes and left-aligned values\n",
    "html_table = df.style.set_properties(**{'text-align': 'left'}) \\\n",
    "                     .format({'Attribute': lambda x: f'<b>{x}</b>'}) \\\n",
    "                     .hide(axis='index') \\\n",
    "                     .to_html()\n",
    "\n",
    "# Display the styled HTML table\n",
    "display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "result_text = emails[0].raw\n",
    "wrapped_text = textwrap.fill(result_text, width=80)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Flow\n",
    "from crewai.flow.flow import listen, start, and_, or_, router\n",
    "\n",
    "class SalesPipeline(Flow):\n",
    "    \n",
    "    @start()\n",
    "    def fetch_leads(self):\n",
    "        # Pull our leads from the database\n",
    "        # This is a mock, in a real-world scenario, this is where you would\n",
    "        # fetch leads from a database\n",
    "        leads = [\n",
    "            {\n",
    "                \"lead_data\": {\n",
    "                    \"name\": \"João Moura\",\n",
    "                    \"job_title\": \"Director of Engineering\",\n",
    "                    \"company\": \"Clearbit\",\n",
    "                    \"email\": \"joao@clearbit.com\",\n",
    "                    \"use_case\": \"Using AI Agent to do better data enrichment.\"\n",
    "                },\n",
    "            },\n",
    "        ]\n",
    "        return leads\n",
    "\n",
    "    @listen(fetch_leads)\n",
    "    def score_leads(self, leads):\n",
    "        scores = lead_scoring_crew.kickoff_for_each(leads)\n",
    "        self.state[\"score_crews_results\"] = scores\n",
    "        return scores\n",
    "\n",
    "    @listen(score_leads)\n",
    "    def store_leads_score(self, scores):\n",
    "        # Here we would store the scores in the database\n",
    "        return scores\n",
    "\n",
    "    @listen(score_leads)\n",
    "    def filter_leads(self, scores):\n",
    "        return [score for score in scores if score['lead_score'].score > 70]\n",
    "\n",
    "    @listen(and_(filter_leads, store_leads_score))\n",
    "    def log_leads(self, leads):\n",
    "        print(f\"Leads: {leads}\")\n",
    "\n",
    "    @router(filter_leads)\n",
    "    def count_leads(self, scores):\n",
    "        if len(scores) > 10:\n",
    "            return 'high'\n",
    "        elif len(scores) > 5:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'low'\n",
    "\n",
    "    @listen('high')\n",
    "    def store_in_salesforce(self, leads):\n",
    "        return leads\n",
    "\n",
    "    @listen('medium')\n",
    "    def send_to_sales_team(self, leads):\n",
    "        return leads\n",
    "\n",
    "    @listen('low')\n",
    "    def write_email(self, leads):\n",
    "        scored_leads = [lead.to_dict() for lead in leads]\n",
    "        emails = email_writing_crew.kickoff_for_each(scored_leads)\n",
    "        return emails\n",
    "\n",
    "    @listen(write_email)\n",
    "    def send_email(self, emails):\n",
    "        # Here we would send the emails to the leads\n",
    "        return emails\n",
    "\n",
    "flow = SalesPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as crewai_flow.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"150%\"\n",
       "            height=\"600\"\n",
       "            src=\"./crewai_flow.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x751909b83320>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='./crewai_flow.html', width='150%', height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
